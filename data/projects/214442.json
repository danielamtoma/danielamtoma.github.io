{
    "rcn": "214442",
    "acronym": "Competing Forecasts",
    "topics": "MSCA-IF-2017",
    "title": "Comparing the Predictive Ability of Forecasting Models",
    "startDate": "01/09/2018",
    "endDate": "31/08/2020",
    "objective": "Constructing accurate predictions on different macroeconomic variables is a key issue for any central bank and other policy making institutions. For example, obtaining accurate inflation forecasts is important for setting interest rates. These institutions typically rely on a set of models to construct their forecasts and the question that often arises is which of these models performs the best in terms of predictive ability. The purpose of this project is to show that, when strong identification on these models is lost (an issue that is prevalent in many models used for prediction), our inference based on standard tests, that compare these models' predictive accuracy, can be misleading.  A policy maker could thus falsely conclude that a particular model outperforms some other models in her set of competing models. This project will answer thus the question of how to perform correct inference about predictions in the setting in which the models are affected by identification deficiencies. To this end, I propose methods that make the standard predictive ability tests robust to this issue, while appropriately accounting for the parameter estimation error. The asymptotic distribution of the statistic will be derived under loss of strong identification. Bootstrap inference will be developed in order to obtain correct critical values. Monte Carlo simulations will analyze the finite sample properties of bootstrap critical values. Empirical studies will illustrate the consequences of using a standard vs. a bootstrap critical value. Results emerging from this project, will be of interest to a large academic community, central banks and other governmental organizations - that could take-up the new knowledge for policy making, as well as businesses that produce predictions - that could improve their forecast evaluation methodologies.",
    "totalCost": "165598,8",
    "ecMaxContribution": "165598,8",
    "coordinator": "ERASMUS UNIVERSITEIT ROTTERDAM",
    "coordinatorCountry": "NL",
    "participants": "",
    "participantCountries": "",
    "projectParticipants": {},
    "calculatedTotalContribution": 0
}